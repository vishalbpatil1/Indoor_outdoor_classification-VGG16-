{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v27bfee6PqCq"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name=\"/content/drive/My Drive/scens_detection/Test_zip.zip\"\n",
    "with ZipFile(file_name,'r') as zip:\n",
    "     zip.extractall()\n",
    "print('---Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmhxZ_aa7fYF"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name=\"/content/drive/My Drive/scens_detection/Train_zip.zip\"\n",
    "with ZipFile(file_name,'r') as zip:\n",
    "     zip.extractall()\n",
    "print(' ---Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9mlA4EOVBJ2"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.15.0\n",
    "#!pip install keras==2.2.4\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version ==',tf.__version__)\n",
    "print('='*20)\n",
    "import keras\n",
    "print('keras version ==',keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZduXzkM4zzcS"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSwqomtT_Dvm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32KnLc45SwqL"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#sns.set_style('darkgrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIQHeaydSw0o"
   },
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "train_path = '/content/Train'\n",
    "valid_path = '/content/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DW_bulbuC7pG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PoJv0Z8Sw0K"
   },
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZVlBgxxA1Iw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lauV9NX7TGS8"
   },
   "outputs": [],
   "source": [
    " # useful for getting number of classes\n",
    "folders = glob('/content/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM0AF0E9WU5T"
   },
   "outputs": [],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZrtdrGCTGfz"
   },
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bchZ-tbhTOd3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQSG2JUXTZ1M"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbODdV1MXqQw"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZH-5LYdTaDj"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56xKwG1PTGk7"
   },
   "outputs": [],
   "source": [
    "epoches=range(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebAQh07fTGkb"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_acc=r.history['accuracy']\n",
    "test_acc=r.history['val_accuracy']\n",
    "train_loss=r.history['loss']\n",
    "test_loss=r.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8ZaKH5mTGfU"
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(epoches,train_loss,\"r--\")\n",
    "plt.plot(epoches,test_loss,\"b-\")\n",
    "plt.legend([\"Traning Loss :\",\"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOWfSUxaHK30"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(epoches,train_acc,\"r--\")\n",
    "plt.plot(epoches,test_acc,\"b-\")\n",
    "plt.legend([\"Traning acuracy :\",\"Test accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Acuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Lo3pX7qHRbY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result=pd.DataFrame({'traing loss':train_loss,'traing accuracy':train_acc,'test loss':test_loss,'test accuracy ':test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AcK4hQdHZBo"
   },
   "outputs": [],
   "source": [
    "#Result Dataframe \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sENrSecksncS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7vOGiPusnvR"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/scens_detection/model_1.h5')\n",
    "#tf.keras.models.save_model(model,filepath='/content/drive/My Drive/mask_detection_vgg.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfOm_ZuptcQM"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from keras.preprocessing import image\n",
    "images_path_indoor=glob('/content/Test/indoor/*')\n",
    "images_path_outdoor=glob('/content/Test/outdoor/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NUPeryPt8-Z"
   },
   "outputs": [],
   "source": [
    "# Prediction for Mask found in testing dataset\n",
    "prediction=[]\n",
    "actual=[]\n",
    "for i in range(len(images_path_indoor)):\n",
    "  img = image.load_img(images_path_indoor[i],target_size=(224,224))\n",
    "  img = np.asarray(img)\n",
    "  class_=['indoor','outdoor']\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  output = model.predict(img)\n",
    "  prediction.append(class_[output.argmax()])\n",
    "  actual.append('indoor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkyBzABV7EPX"
   },
   "outputs": [],
   "source": [
    "# Prediction for No Mask found in testing dataset\n",
    "\n",
    "for i in range(len(images_path_outdoor)):\n",
    "  img = image.load_img(images_path_outdoor[i],target_size=(224,224))\n",
    "  img = np.asarray(img)\n",
    "  class_=['indoor','outdoor']\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  output = model.predict(img)\n",
    "  prediction.append(class_[output.argmax()])\n",
    "  actual.append('outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnUqhjaS7p08"
   },
   "outputs": [],
   "source": [
    "print(classification_report(actual,prediction,target_names=class_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQKn12bO7pzr"
   },
   "outputs": [],
   "source": [
    "# classification report plot\n",
    "cr=pd.DataFrame()\n",
    "cr['Prcision']=[0.90,0.85,0.87,0.88]\n",
    "cr['Recall']=[0.87,0.88,0.88,0.88]\n",
    "cr['F1-score']=[0.88,0.86,0.88,0.88]\n",
    "cr.index=['indoor','outdoor','macro avg','weigthed avg']\n",
    "#plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cr,annot=True,fmt='.3f',vmin=0,vmax=1,linewidths=2,cmap='Blues')\n",
    "plt.title('VGG16 Model--classification report')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcUse7L79uis"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(actual,prediction)\n",
    "cm=pd.DataFrame(cm)\n",
    "cm.index=cm.columns=class_\n",
    "sns.heatmap(cm,annot=True,fmt='.0f',vmin=0,vmax=140,linewidths=2,cmap='Blues')\n",
    "plt.title('VGG16 Model--Confusion matrix')\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('actual class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udi_j47r9usb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0dR91rwtYRl"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  img = image.load_img(images_path_indoor[i],target_size=(224,224))\n",
    "  img = np.asarray(img)\n",
    "  plt.imshow(img)\n",
    "  #class_=['Mask found','Mask not found']\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  #from keras.models import load_model\n",
    "  #saved_model = load_model(\"vgg16_1.h5\")\n",
    "  output = model.predict(img)\n",
    "  plt.title('Prediction = '+str(class_[output.argmax()]))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbraDFfMtYeC"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  img = image.load_img(images_path_outdoor[i],target_size=(224,224))\n",
    "  img = np.asarray(img)\n",
    "  plt.imshow(img)\n",
    "  #class_=['indoor','outdoor']\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  #from keras.models import load_model\n",
    "  #saved_model = load_model(\"vgg16_1.h5\")\n",
    "  output = model.predict(img)\n",
    "  plt.title('Prediction = '+str(class_[output.argmax()]))\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "scens_detection_GPU_vgg16.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
